{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS_Uni_4_Sprint_3_Challenge.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "kernelspec": {
      "name": "u4-s3-dnn",
      "language": "python",
      "display_name": "U4-S3-DNN (Python 3.7)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS6nIIcFXKAL",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on SageMaker, Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe the components of an autoencoder\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - RNNs\n",
        "\n",
        "Use an RNN/LSTM to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "outputId": "b5419ee5-5555-4ff8-c122-ceebc1ff5026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "44ef8db5-86c0-4b8f-e269-8aca53e589b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4REcElYfGZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_to_int = dict((c, i) for i, c in enumerate(word_index)) #enumerate returns index & value. Convert it to dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gwCfhhXfYYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = char_to_int[\"and\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym94wY2xff0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1b6d7fa-dc53-4807-8919-75ec0dc2d788"
      },
      "source": [
        "test"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnL1YyjgZlZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUUuhDh6cUFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd2b35e4-d6a2-4a3d-85ff-50595e37a81b"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982,), (8982,), (2246,), (2246,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIBmoS02cUXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4a0ea19-68a4-4196-efd7-e8e640de2986"
      },
      "source": [
        "number_words = len(word_index) # the number of unique characters\n",
        "\n",
        "print(\"number words:\", number_words)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number words: 30979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf4J_lEpcUnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c502ee76-598e-46eb-e113-e1b357111dbf"
      },
      "source": [
        "#reshapes y variables\n",
        "y_train = y_train.reshape(y_train.shape[0], 1)\n",
        "y_test = y_test.reshape(y_test.shape[0], 1)\n",
        "\n",
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982, 1), (2246, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8937e049-1d4c-4e56-e58f-d7c21fa75b49"
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "\n",
        "batch_size = 46\n",
        "max_features = len(word_index.values())\n",
        "maxlen = 200\n",
        "\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "\n",
        "\n",
        "#print('Build model...')\n",
        "# TODO - your code!\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8982 train sequences\n",
            "2246 test sequences\n",
            "Pad sequences (samples x time)\n",
            "X_train shape: (8982, 200)\n",
            "X_test shape: (2246, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpSzL_hFgaQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "689d4ef6-2573-4cd8-bac7-59135497e805"
      },
      "source": [
        "#create sequential model\n",
        "model_1 = Sequential()\n",
        "\n",
        "model_1.add(Embedding(max_features+1, 256)) #using +1 because of error when value = max value\n",
        "\n",
        "model_1.add(LSTM(256, dropout=0.2))\n",
        "\n",
        "model_1.add(Dense(46, activation='softmax'))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI4aR6JSXKBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1a1cef52-a240-40c1-8dc8-21f312a2995e"
      },
      "source": [
        "# You should only run this cell once your model has been properly configured\n",
        "\n",
        "model_1.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model_1.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score, acc = model_1.evaluate(X_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 8982 samples, validate on 2246 samples\n",
            "8982/8982 [==============================] - 73s 8ms/sample - loss: 1.6274 - acc: 0.5700 - val_loss: 1.5658 - val_acc: 0.5917\n",
            "2246/2246 [==============================] - 4s 2ms/sample - loss: 1.5658 - acc: 0.5917\n",
            "Test score: 1.565806358654586\n",
            "Test accuracy: 0.5917186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP-tdf65XKBY",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Data Question\n",
        "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
        "pad_sequences is used to ensure that all sequences in a list have the same length. Pad_sequences changes the length of every sequence to be the same(maxlen) by adding the same value to the start to each sequence to increase it up to the max length. For example if it is over the max length, it is shortened to be at the max length. This is important because the sequences are the input to the neural network, therefore they've to be the same.\n",
        "Please add your answer in markdown here.\n",
        "\n",
        "## RNNs versus LSTMs\n",
        "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
        "LSTM networks have an advantage over RNNs because of the maths involved in the LSTM. The maths involved in the LSTM calculations avoids the issue of diminissing gradient. After a certain number of epochs RNNs the gradient values in an RNN for events in the far past will be so small that a computer can interpret it as 0. The LSTM is a great tool for anything that has a sequence. RNN addresses an issue by including a feedback look which serves as some sort of memory.\n",
        "Please add your answer in markdown here.\n",
        "\n",
        "## RNN / LSTM Use Cases\n",
        "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
        "1: Weather/climate prediction: We can use past weather patterns & reoccuring or current atomspheric conditions to predict weather patterns\n",
        "2. Financial predictions/stock broker: they can attempt to predict price/sale changes based on previous pattern of price/sale changes\n",
        "3. Speech or text prediction: we can find patterns in a series of words to predict next word or generate future text that follows a certain or similar pattern\n",
        "Please add your answer in markdown here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "outputId": "71d32026-1ab6-4f21-fd60-48470e0def14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install google_images_download"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_images_download\n",
            "  Downloading https://files.pythonhosted.org/packages/18/ed/0319d30c48f3653802da8e6dcfefcea6370157d10d566ef6807cceb5ec4d/google_images_download-2.8.0.tar.gz\n",
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\r\u001b[K     |▍                               | 10kB 26.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 31.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 35.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 39.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51kB 41.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61kB 43.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71kB 43.0MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 44.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 92kB 44.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102kB 45.9MB/s eta 0:00:01\r\u001b[K     |████                            | 112kB 45.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 122kB 45.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 133kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 143kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 153kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 163kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 174kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 184kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 194kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 204kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 215kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 225kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 235kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 245kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 256kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 266kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 276kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 286kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 296kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 307kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 317kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 327kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 337kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 348kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 358kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 368kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 378kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 389kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 399kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 409kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 419kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 430kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 440kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 450kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 460kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 471kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 481kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 491kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 501kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 512kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 522kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 532kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 542kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 552kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 563kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 573kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 583kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 593kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 604kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 614kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 624kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 634kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 645kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 655kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 665kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 675kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 686kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 696kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 706kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 716kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 727kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 737kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 747kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 757kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 768kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 778kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 788kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 798kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 808kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 819kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 829kB 45.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 839kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 849kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 860kB 45.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 870kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 880kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 890kB 45.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 901kB 45.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 911kB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium->google_images_download) (1.24.3)\n",
            "Building wheels for collected packages: google-images-download\n",
            "  Building wheel for google-images-download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-images-download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14550 sha256=f8150e00ac52ad4874b9b96986b9f563319cd17e90415693c2900e24f4d7440c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/28/ad/f56e7061e1d2a9a1affe2f9c649c2570cb9198dd24ede0bbab\n",
            "Successfully built google-images-download\n",
            "Installing collected packages: selenium, google-images-download\n",
            "Successfully installed google-images-download-2.8.0 selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "b1fc10dc-fccc-46ba-90fa-a0e0a98cbd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "arguments = {\"keywords\": \"lilly frog pond\", \"limit\": 5, \"print_urls\": True}\n",
        "absolute_image_paths = response.download(arguments)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = lilly frog pond\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "\n",
            "Unfortunately all 5 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
            "\n",
            "Errors: 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
        "\n",
        "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goals* \n",
        "- Check for fish or other labels\n",
        "- Create a matplotlib visualizations of the images and your prediction as the visualization label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaT07ddW3nHz",
        "colab": {}
      },
      "source": [
        "# You've got something to do in this cell. ;)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "def process_img_path(img_path):\n",
        "  return image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "def img_contains_frog(img):\n",
        "    \"\"\" Scans image for Frogs\n",
        "    \n",
        "    Should return a boolean (True/False) if a frog is in the image.\n",
        "    \n",
        "    Inputs:\n",
        "    ---------\n",
        "    img:  Precrossed image ready for prediction. The `process_img_path`             function should already be applied to the image. \n",
        "    \n",
        "    Returns: \n",
        "    ---------\n",
        "    frogs (boolean):  TRUE or FALSE - There are frogs in the image.\n",
        "    \n",
        "    \"\"\"\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    model = ResNet50(weights='imagenet')\n",
        "    features = model.predict(x)\n",
        "    results = decode_predictions(features, top=3)[0]\n",
        "    print(results)\n",
        "    for entry in results:\n",
        "      if entry[1] == 'bullfrog' or entry[1] == 'tree frog' or entry[1] == 'tailed frog':\n",
        "        return entry[2]\n",
        "            \n",
        "    return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM5GmykItTM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for path in absolute_image_paths[0]['lilly frog pond']:\n",
        "  img_contains_frog(process_img_path(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EfY-nzmXKCM",
        "colab_type": "text"
      },
      "source": [
        "#### Stretch Goal: Displaying Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EppIsWQE9V3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import requests\n",
        "def process_img_path(img_path):\n",
        "  return image.load_img(img_path, target_size=(224, 224))\n",
        "def img_contains_fish(img):\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  model = ResNet50(weights='imagenet')\n",
        "  features = model.predict(x)\n",
        "  results = decode_predictions(features, top=3)[0]\n",
        "  print(results)\n",
        "  for entry in results:\n",
        "    if 'fish' in entry[1]:\n",
        "      return entry[2]\n",
        "  return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcNcTUc99lXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for path in absolute_image_paths[0]['lilly frog pond'][:5]:\n",
        "  img_contains_fish(process_img_path(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J-XyZDhzpAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "59dd3692-d217-46f9-9bb7-be68901b4914"
      },
      "source": [
        "f, axarr = plt.subplots(2,2)\n",
        "imgs, frogs = display_predictions(absolute_image_paths[0]['lilly frog pond'])\n",
        "for x,y in [(0,0),(0,1), (1,0), (1,1)]:  \n",
        "    axarr[x,y].imshow(np.squeeze(imgs[x], axis=0) / 255)\n",
        "    axarr[x,y].set_title(f\"Frog: {frogs[x]}\")\n",
        "    axarr[x,y].axis('off')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-a6c8d7bdc9fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabsolute_image_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lilly frog pond'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Frog: {frogs[x]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA/TcjOXpJ7ZuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "__*Your Answer:*__ \n",
        "Generally autoencoders can be good at removing noises from imput images, it can be viewed as being useful for removing noise from pictures such as astronomical imaging. Also An Autoencoder is an algorithm that applies backpropagation, setting the target values to be equal to the inputs. It is used to reduce the size of our inputs into a smaller representation. They are also used for Dimentionality Reduction, Image Compression. Autoencoders can also be used to recolor images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "\n",
        "I believe my strongest area for now as a Data Scientist is communication. My communication skills are above average because I've been told that I'm able to explain technical things to non-technical people. I believe this is a good skill for us because we would need to explain analyses of data to non-technical people in a non-technical but detailed manner. Also I really do enjoy cleaning and analysing data.\n",
        "\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "\n",
        "I'd definitely like to learn more about dealing with \"big data\", particularly when the data is unstructured. In the real world, data is often messy but valuable. I believe I need to sharpen my skills in this area. Also I'd like to master the act of finding which libraries are needed to import and format the data, use the documentation to learn the libraries enough to do what is needed.\n",
        "\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "Genuinely I look at Data Science as the future. I believe we are at a point where data would be equivalent to currency. I see data science growing in fields like automobile, sports(my field), entertainment. I also see data science in the next 5years as an important study in helping with Climate change & global warmings.\n",
        "\n",
        "- What are the threats posed by AI to our society?\n",
        "\n",
        "Job displacement is the most immediate treat. If we don't accidentally create harmful AGI and manage to create it in a manner that allows it to augment human intelligence, society will fundamentally change on a massive and drastic scale. I believe there would come a time where we won't work for currency anymore because AGI would take more than half control of the work force. \n",
        "Also another threat posed by AI to our society is weaponized AI errors. I still believe humans are the greatest threat to humans. \n",
        "- How do you think we can counteract those threats? \n",
        "\n",
        "To avoid job loss, we could regulate AI. Although some may argue that would put us behind countried which don't regulate AI. I think it should be a world regulation where all countries are involved. I personally believe that once AI starts taking over the jobs, then we would turn our attention to some other kind of hobbies. And that would be a time where we don't have to work for currency. \n",
        "\n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "\n",
        "Yes, but probably not before 2050. There's not a strong commercial incentive behind AGI research right now and consciousnesss seems to become more mystifying the more we learn about it.\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX52uZ4XXKCv",
        "colab_type": "code",
        "colab": {},
        "outputId": "34b97d31-1a87-4c8f-d90e-2773db730fb1"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}